
# Define the DQN Algorithm Parameters
learning_rate: 0.001
discount_factor: 0.99
# Initial exploration probability
exploration_prob: 0.80
# Decay rate of exploration probability
exploration_decay: 0.08
# Minimum exploration probability
min_exploration_prob: 0.1

num_actions: 12

epsilon_discount: 0.999 # 1098 eps to reach 0.1
nepisodes: 100000
nsteps: 10000

# Environment Parameters
desired_pose:
    x: 1.0
    y: 0.0
    z: 0.21933
desired_force: 31.57895636 # In Newtons, normal contact force when stanting still with 9.81 gravity
#3.219057733 suma de masas
desired_yaw: 0.0 # Desired yaw in radians for the hopper to stay
max_height: 4.5   # in meters
min_height: 0.3417   # in meters
max_incl: 1.3      # in rads
running_step: 0.001   # in seconds
joint_increment_value: 0.1  # in radians

done_reward: -1000.0 # reward
static_reward: -1000.0 # reward
alive_reward: 100.0 # reward

interval_reward: 100.0 # reward

weight_r1: -5.0 # Weight for joint positions ( joints in the zero is perfect )
weight_r2: -0.4 # Weight for joint efforts ( no efforts is perfect )
weight_r3: 1.0 # Weight for contact force similar to desired ( weight of monoped )
weight_r4: 1.0 # Weight for orientation ( vertical is perfect )
weight_r5: 5.0 # Weight for distance from desired point ( on the point is perfect ) 
weight_interval: 1.3